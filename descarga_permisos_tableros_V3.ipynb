{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrapping the List of People With Access to PBI Reports\n",
    "\n",
    "**Author:** Cristian C. Velandia C.\n",
    "\n",
    "**Description:** This notebook shows how to configure Selenium Chrome Driver and perform a simple web scarpping task to create an inventory in excel about people with access to a Power BI report, This was done this way given the fact that Power BI does not offer a simple way to extract those lists, not even for admins. This offers a simple and effective solution to thtat problematic. \n",
    "\n",
    "**Input:** csv file with the following columns with no headers\n",
    "* company: The name of the company that belongs to the report\n",
    "* Working Area: Power BI work area name, This could be extracted during the process but for simplicity while extracting the URLs can be added to the list \n",
    "* PBI Report Name: Report name, This could be extracted during the process but for simplicity while extracting the URLs can be added to the list \n",
    "* URL: The URL of the Direct Access section of the Power BI Report\n",
    "\n",
    "**Output:** An Excel File that contains the list of people with access and the permissions. \n",
    "\n",
    "**Main Libraries to be used:** \n",
    "- selenium                  4.16.0\n",
    "- pandas                    2.1.1\n",
    "- openpyxl                  3.1.2\n",
    "\n",
    "**Python Version:** Python 3.9.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.actions.wheel_input import ScrollOrigin\n",
    "\n",
    "import time \n",
    "import os \n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for chrome driver data\n",
    "Folder = \"Chrome_Driver_Data\"\n",
    "# Parent Directory path\n",
    "Directorio = \"C:\\\\\"\n",
    "#create folder path \n",
    "path_chrome = os.path.join(Directorio, Folder)\n",
    "\n",
    "CHECK_FOLDER = os.path.isdir(path_chrome)\n",
    "\n",
    "# If folder doesn't exist, then create it\n",
    "if not CHECK_FOLDER:\n",
    "    os.makedirs(path_chrome)\n",
    "\n",
    "# Define the driver to use\n",
    "chromeOptions = webdriver.ChromeOptions()\n",
    "# add extra configuration options to the driver \n",
    "chromeOptions.add_argument(\"--start-maximized\") \n",
    "#chromeOptions.add_argument(\"--window-size=1300,200\")\n",
    "chromeOptions.add_argument(\"--disable-gpu\") \n",
    "chromeOptions.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"]) \n",
    "chromeOptions.add_argument(\"user-data-dir=\" + path_chrome) \n",
    "chromeOptions.add_argument(\"--homepage=about:blank\") #start on blank page to avoid wasting time\n",
    "\n",
    "#Automatically download the driver using the service method from chrome\n",
    "service = Service()\n",
    "driver = webdriver.Chrome(service = service, options = chromeOptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read URLs to all the power BI Direct access page\n",
    "enlaces = pd.read_csv(\"enlaces tableros_nata.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cicle to access each URL in the csv file (LOGIN manually before running this cell)\n",
    "\n",
    "for index, row in enlaces.iterrows():\n",
    "\n",
    "    URL = row[3] #Extract URL\n",
    "    entidad = row[0] #Extract compnay name \n",
    "    area = row[1] #Extract working area\n",
    "    tablero = row[2] #Extract pbi report name \n",
    "\n",
    "    driver.get(URL) #Send the URL to the chrome driver\n",
    "\n",
    "    print(tablero) # Print to know wht is being processed\n",
    "\n",
    "    time.sleep(8) # Wait for webpage to load\n",
    "\n",
    "    accesos = [] # Empty list for storing the file\n",
    "\n",
    "    # Scroll down 20 times while searching for each line in the table of access\n",
    "    for i in range(20): \n",
    "        for j in range(1, 51, 1):\n",
    "            try:\n",
    "                element = driver.find_element(By.XPATH, '//*[@id=\"artifactContentView\"]/div[1]/div[{0}]'.format(j)) #Find element of the table\n",
    "                accesos.append(element.text) #append element to the list\n",
    "                #print('//*[@id=\"artifactContentView\"]/div[1]/div[{0}]'.format(j))\n",
    "            except:\n",
    "                #break if element not found\n",
    "                #print(\"break\")\n",
    "                break\n",
    "            \n",
    "        scroll_origin = ScrollOrigin.from_element(element) # scroll wodn from last element found\n",
    "        ActionChains(driver).scroll_from_origin(scroll_origin, 0, 1500).perform() # scroll 1500 pixels\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Process Scraped data with pandas\n",
    "    accesos_df = pd.DataFrame(accesos) #Create dataframe based on the list\n",
    "    accesos_df_final = accesos_df[0].str.split(\"\\n\", expand = True).copy() #split text to create a table\n",
    "    accesos_df_final.rename(columns = {0: \"iniciales\", 1:\"Persona\", 2:\"Correo\", 3:\"Permisos\"}, inplace=True)\n",
    "    accesos_df_final.drop_duplicates(inplace=True) #drop duplicates generate in scrolling\n",
    "    accesos_df_final = accesos_df_final.apply(lambda x: x.shift(periods=1) if x[\"Permisos\"] is None else x, axis = 1) # Shift cells right for rows without intials\n",
    "    \n",
    "    accesos_df_final[\"Entidad\"] = entidad\n",
    "    accesos_df_final[\"Area\"] = area\n",
    "    accesos_df_final[\"Tablero\"] = tablero\n",
    "    accesos_df_final[\"Url\"] = URL\n",
    "    id = str(index) # add index as id of the access\n",
    "    accesos_df_final.to_excel(\"{0}_accesos {1} {2} {3} {4}.xlsx\".format(id, entidad, area, tablero, str(date.today()))) #Save file to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close selenium Driver\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "varios_selenium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
